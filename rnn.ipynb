{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddJTimH4OWHF"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF_QciAbOWHI",
        "outputId": "b3cc29cb-f82d-43ae-8c8e-759ac28a446f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(180000)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autosaving every 180 seconds\n"
          ]
        }
      ],
      "source": [
        "# As usual, a bit of setup\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%autosave 180\n",
        "\n",
        "def rel_error(x, y):\n",
        "    \"\"\" returns relative error \"\"\"\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FRP7jUjOWHJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8O_tlIhOWHJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# set sizes \n",
        "time_steps = 12\n",
        "batch_size = 4\n",
        "input_size = 3\n",
        "hidden_size = 2\n",
        "\n",
        "# create input data with shape [batch_size, time_steps, num_features]\n",
        "np.random.seed(137)\n",
        "input_data = torch.randn(batch_size, time_steps, input_size, dtype = torch.float32)\n",
        "\n",
        "initial_state = torch.randn(batch_size, hidden_size, dtype = torch.float32).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_9x0BmbOWHK"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kngI-8IiOWHK"
      },
      "outputs": [],
      "source": [
        "t_rnn = nn.RNN(input_size, hidden_size, num_layers = 1, batch_first = True)\n",
        "\n",
        "\n",
        "\n",
        "t_gru = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    t_rnn_outputs, t_rnn_final_state = t_rnn(input_data, initial_state)\n",
        "    t_gru_outputs, t_gru_final_state = t_gru(input_data, initial_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWj6uTLcOWHL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vwi0kbIOWHL"
      },
      "outputs": [],
      "source": [
        "from rnn_param_helper import get_rnn_params, get_gru_params\n",
        "\n",
        "wt_h, wt_x, bias = get_rnn_params(t_rnn)\n",
        "\n",
        "\n",
        "\n",
        "linear_trans_r, linear_trans_z, linear_trans_n = get_gru_params(t_gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow9FwKN9OWHL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVN0P_GyOWHM",
        "outputId": "d486713c-b968-491e-aaed-63ddfb1ae938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference between your RNN implementation and tf RNN 3.4710562192909463e-06\n",
            "Difference between your GRU implementation and tf GRU 5.0752533014423674e-06\n"
          ]
        }
      ],
      "source": [
        "from implementation import rnn,gru\n",
        "\n",
        "nprnn_outputs, nprnn_final_state = rnn(wt_h, wt_x, bias, initial_state.numpy(), input_data.numpy())\n",
        "\n",
        "\n",
        "print(\"Difference between your RNN implementation and tf RNN\", \n",
        "                     rel_error(t_rnn_outputs.numpy(), nprnn_outputs) + rel_error(t_rnn_final_state.numpy(), nprnn_final_state))\n",
        "\n",
        "npgru_outputs, npgru_final_state = gru(linear_trans_r, linear_trans_z, linear_trans_n, initial_state.numpy(), input_data.numpy())\n",
        "\n",
        "print(\"Difference between your GRU implementation and tf GRU\", \n",
        "      rel_error(t_gru_outputs.numpy(), npgru_outputs) + rel_error(t_gru_final_state.numpy(), npgru_final_state))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6E_Y2AOWHM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO5OxqbjOWHM",
        "outputId": "8d858ce9-49d6-45b7-d4f4-2b6762fbc444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference between RNN and a special GRU 3.2550126e-06\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from implementation import init_gru_with_rnn\n",
        "\n",
        "linear_trans_r, linear_trans_z, linear_trans_n = init_gru_with_rnn(wt_h, wt_x, bias)\n",
        "\n",
        "# concatenate these parameters to initialize GRU kernels\n",
        "kernel_init = np.concatenate([linear_trans_r[0], linear_trans_z[0], linear_trans_n[0]], axis=1).T\n",
        "rec_kernel_init = np.concatenate([linear_trans_r[2], linear_trans_z[2], linear_trans_n[2]], axis=1).T\n",
        "bias_init0 = np.concatenate([linear_trans_r[1], linear_trans_z[1], linear_trans_n[1]], axis=0)\n",
        "bias_init1 = np.concatenate([linear_trans_r[3], linear_trans_z[3], linear_trans_n[3]])\n",
        "\n",
        "grurnn = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True)\n",
        "wt_x1, wt_h1, bias_ih1, bias_hh1 = grurnn._flat_weights\n",
        "\n",
        "wt_x1.data = torch.tensor(kernel_init, dtype =torch.float32)\n",
        "wt_h1.data = torch.tensor(rec_kernel_init, dtype = torch.float32)\n",
        "bias_ih1.data = torch.tensor(bias_init0, dtype = torch.float32)\n",
        "bias_hh1.data = torch.tensor(bias_init1, dtype = torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    t_rnn_outputs, t_rnn_final_state = t_rnn(input_data, initial_state)\n",
        "    grurnn_outputs, grurnn_final_state = grurnn(input_data, initial_state)\n",
        "\n",
        "\n",
        "print(\"Difference between RNN and a special GRU\", rel_error(t_rnn_outputs.numpy(), grurnn_outputs.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VPP-SzhOWHN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elYx3bk5OWHN"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dQw7zdSOWHN",
        "outputId": "0a422601-2415-4556-9ae6-f175df474c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference between a later hidden state and the initial state is 0.0\n"
          ]
        }
      ],
      "source": [
        "from implementation import init_gru_with_long_term_memory\n",
        "\n",
        "\n",
        "\n",
        "linear_trans_r, linear_trans_z, linear_trans_n = init_gru_with_long_term_memory(input_size, hidden_size)\n",
        "\n",
        "kernel_init = np.concatenate([linear_trans_r[0], linear_trans_z[0], linear_trans_n[0]], axis=1).T\n",
        "rec_kernel_init = np.concatenate([linear_trans_r[2], linear_trans_z[2], linear_trans_n[2]], axis=1).T\n",
        "bias_init0 = np.concatenate([linear_trans_r[1], linear_trans_z[1], linear_trans_n[1]], axis=0)\n",
        "bias_init1 = np.concatenate([linear_trans_r[3], linear_trans_z[3], linear_trans_n[3]])\n",
        "\n",
        "gru2 = nn.GRU(input_size, hidden_size, num_layers = 1, batch_first = True)\n",
        "wt_xg, wt_hg, bias_ihg, bias_hhg = gru2._flat_weights\n",
        "\n",
        "\n",
        "wt_xg.data = torch.tensor(kernel_init, dtype =torch.float32)\n",
        "wt_hg.data = torch.tensor(rec_kernel_init, dtype = torch.float32)\n",
        "bias_ihg.data = torch.tensor(bias_init0, dtype = torch.float32)\n",
        "bias_hhg.data = torch.tensor(bias_init1, dtype = torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs, _ = gru2(input_data, initial_state)\n",
        "    outputs = outputs.numpy()\n",
        "    \n",
        "    \n",
        "    print('Difference between a later hidden state and the initial state is', np.mean(np.abs(outputs[:, 10, :] - initial_state[0, :, :].numpy())))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PijZUtblOWHN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8aUzvaNOWHN",
        "outputId": "c1c9a6e0-9078-42c2-9501-19b8dbdd6ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference between my output and torch output is  2.0640801e-08\n"
          ]
        }
      ],
      "source": [
        "from rnn_param_helper import get_mha_params\n",
        "from implementation import mha\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "time_steps = 8\n",
        "input_size = 10\n",
        "num_heads = 5\n",
        "\n",
        "input_data = torch.randn(batch_size, time_steps, input_size, dtype = torch.float32)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    t_mha = nn.MultiheadAttention(embed_dim=input_size, num_heads=num_heads, dropout=0.0, bias=False, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=True)\n",
        "\n",
        "    t_output, _ = t_mha(input_data, input_data, input_data, need_weights=False)\n",
        "\n",
        "\n",
        "Wq, Wk, Wv, Wo = get_mha_params(t_mha)\n",
        "\n",
        "output = mha(Wq, Wk, Wv, Wo, input_data )\n",
        "\n",
        "print('Difference between my output and torch output is ', np.mean(np.abs(output - t_output.numpy())))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flEiDqscOWHO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}